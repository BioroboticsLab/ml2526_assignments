{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2.1 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit your solution of this notebook in the Whiteboard at the corresponding Assignment entry as .ipynb-file and as .pdf. <br><br>\n",
    "Please do **NOT** rename the file!\n",
    "\n",
    "#### State both names of your group members here:\n",
    "[Jane and John Doe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Info/Details - Assignment 2.1:\n",
    "\n",
    "The assignment will be graded semi-automatically, which means that your code will be tested against a set of predefined test cases and qualitatively assessed by a human. This will speed up the grading process for us.\n",
    "\n",
    "* For passing the test scripts: \n",
    "    - Please make sure to **NOT** alter predefined class or function names, as this would lead to failing of the test scripts.\n",
    "    - Please do **NOT** rename the files before uploading to the Whiteboard!\n",
    "\n",
    "* **(RESULT)** tags indicate checkpoints that will be specifically assessed by a human.\n",
    "\n",
    "* You will pass the assignment if you pass the majority of test cases and we can at least confirm effort regarding the **(RESULT)**-tagged checkpoints per task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1.1 - kMeans\n",
    "\n",
    "kMeans is an unsupervised learning algorithm that partitions n observations into k clusters. Each observation belongs to the cluster with the nearest mean (cluster center or centroid).\n",
    "\n",
    "\n",
    "### 1. kMeans Implementation\n",
    "* Implement the kMeans clustering algorithm using `numpy` only. Use the `KMeans` class structure below. **(RESULT)**\n",
    "* Test the convergence of your implementation by creating a 2D synthetic dataset yourself. Report on the convergence. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, k=3, max_iters=100, tol=1e-4, random_state=None):\n",
    "        \"\"\"\n",
    "        Initialize KMeans clusterer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        k : int\n",
    "            Number of clusters\n",
    "        max_iters : int\n",
    "            Maximum number of iterations\n",
    "        tol : float\n",
    "            Tolerance for convergence (change in centroids)\n",
    "        random_state : int or None\n",
    "            Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.max_iters = max_iters\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        self.labels_ = None\n",
    "    \n",
    "    def initialize_centroids(self, X):\n",
    "        \"\"\"\n",
    "        Initialize cluster centers using random selection from data points.\n",
    "        \"\"\"\n",
    "        # TODO: Implement this method\n",
    "        pass\n",
    "    \n",
    "    def initialize_centroids_plusplus(self, X): # for the following Subtask\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit the KMeans model to data X.\n",
    "        \"\"\"\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "            \n",
    "        # TODO: Implement this function\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict cluster labels for new data.\n",
    "        \"\"\"\n",
    "        # TODO: Implement this function\n",
    "        pass\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"\n",
    "        Perform KMeans clustering and return cluster labels.\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.labels_\n",
    "    \n",
    "    # TODO: Feel free to add any additional helper functions you need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. kMeans++ initialization\n",
    "\n",
    "* Implement the kMeans++ initialization method in the KMeans class. **(RESULT)**\n",
    "* Compare the convergence speed of kMeans with random initialization and kMeans++ initialization on your synthetic dataset from Part 1. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement and the kMeans++ initialization function 'initialize_centroids_plusplus' in the KMeans class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualization of Cluster Quality\n",
    "\n",
    "\n",
    "* Visualize the clustering results of your kMeans implementation on a synthetic 2D dataset with at least 4 clusters using matplotlib. **(RESULT)**\n",
    "* Determine the optimal number of clusters using the elbow method. Report on your findings using a simple plot. **(RESULT)**\n",
    "* Report on the silhouette score of your clustering results for the optimal k and k-1. **(RESULT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1.2 - DBSCAN (BONUS)\n",
    "\n",
    "DBSCAN is a density-based clustering algorithm that groups together points that are closely packed together, marking outliers points that lie alone in low-density regions.\n",
    "\n",
    "* Implement the DBSCAN algorithm using `numpy` only. Use the `DBSCAN` class structure below. **(RESULT)**\n",
    "* Test your DBSCAN implementation on a synthetic 2D dataset with noise. Visualize the clustering results using matplotlib. **(RESULT)**\n",
    "* Compare the performance of your DBSCAN implementation with your kMeans implementation on the same synthetic 2D dataset using silhouette score as a metric. Please use the same random seed to make it comparable. **(RESULT)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque   # Useful for efficient BFS implementation (FIFO) for iterating through neighboring points\n",
    "\n",
    "class DBSCAN:\n",
    "    def __init__(self, eps=0.5, min_samples=5, metric='euclidean'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        eps : float\n",
    "            Maximum distance between two samples for them to be considered neighbors\n",
    "        min_samples : int\n",
    "            Number of samples in a neighborhood for a point to be considered a core point\n",
    "            (including the point itself)\n",
    "        metric : str\n",
    "            Distance metric to use ('euclidean' or 'manhattan')\n",
    "        \"\"\"\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.metric = metric\n",
    "        self.labels_ = None\n",
    "        self.core_sample_indices_ = None\n",
    "        self.components_ = None\n",
    "        self.n_clusters_ = None\n",
    "        self.n_noise_ = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Perform DBSCAN clustering.\n",
    "        \"\"\"\n",
    "        # TODO: Implement this function\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X_new):\n",
    "        \"\"\"\n",
    "        Predict the closest cluster for new points.\n",
    "        Note: New points can only be assigned to existing clusters or marked as noise.\n",
    "        \"\"\"\n",
    "        # TODO: Implement this function\n",
    "        pass\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"\n",
    "        Perform DBSCAN clustering and return cluster labels.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Congratz, you made it! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
